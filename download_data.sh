#!/bin/bash

function download() {
    url=$1
    dest=$2

    response=$(curl -X GET ${url} -o -)
    format=$(echo ${response} | jq -r .format)
    if [ "${format}" = "base64" ] ; then
        echo ${response} | jq -j .content | base64 -d > $dest
    elif [ "${format}" = "text" ] ; then
        echo ${response} | jq -j .content > $dest
    else
        echo "Format ${format} of file ${dest} not supported"
        echo ${response} | jq -j .content > $dest
    fi
}

notebook_created="no"

function get_notebook() {
    ## Creates a new notebook if needed. Sets flag to delete if
    ## notebook was re-created.
    apiurl=$1
    sessionid=$2
    serviceid=$3
    svcinfo=`curl --silent -X GET "${apiurl}/${serviceid}" -H  "accept: application/json"`
    if [ $(echo ${svcinfo} | jq -j .sessionId) = "${sessionid}" ] ; then
        return ## NOTEBOOK_URL unchanged.
    fi
    
    svcinfo=`curl --silent -X POST "${apiurl}" -H  "accept: application/json" \
                  -H  "Content-Type: application/json" -d "{\"sessionId\":\"${sessionid}\"}"`
    notebook_created="yes"
    
    svcurl=`echo ${svcinfo} | jq -j .serviceURL`
    if [ "${svcurl}" = "null" ] ; then
        echo "Session ${sessionid} no longer exists. Cannot download data."
        exit 1
    fi

    SERVICE_ID=`echo ${svcinfo} | jq -j .id`
    echo "Wait for service ${SERVICE_ID} to be re-created at ${svcurl}."
    while ! curl --silent -IL -X GET ${svcurl} | grep "200 OK" ; do
        sleep 5
    done
    NOTEBOOK_URL=${svcurl}
}

function delete_notebook() {
    apiurl=$1
    if [ "${notebook_created}" = "yes" ] ; then
        curl -X DELETE "${apiurl}/${SERVICE_ID}" -H  "accept: */*"
    fi
}

function download_working_dir_data() {
    if [ ! -e download_filelist.dat ] ; then
        echo "Nothing to download from working dir."
        return
    fi
    apiurl=$1
    for file in `cat download_filelist.dat` ; do
        download ${apiurl}/${file} ${HOME}/${file}
    done
}

conda install -y -c conda-forge curl jq || exit 1


# =======================================================
# Everything below here is generated by the snapshot job:
# =======================================================
NOTEBOOK_URL=https://swirrl.climate4impact.eu/swirrl/jupyter/b4c529be-bda6-4ab2-a2f8-8084464b022b
SERVICE_ID=b4c529be-bda6-4ab2-a2f8-8084464b022b
get_notebook https://swirrl.climate4impact.eu/swirrl-api/v1.0/notebook 502afa75-6ecb-469f-9472-315339e1dd38 b4c529be-bda6-4ab2-a2f8-8084464b022b
mkdir -p ~/data/staginghistory/stage.00001
download ${NOTEBOOK_URL}/api/contents/data/staginghistory/stage.00001/tas_day_EC-Earth3_ssp585_r101i1p1f1_gr_20160101-20161231.nc ~/data/staginghistory/stage.00001/tas_day_EC-Earth3_ssp585_r101i1p1f1_gr_20160101-20161231.nc
download ${NOTEBOOK_URL}/api/contents/data/staginghistory/stage.00001/swirrl_fileinfo.json ~/data/staginghistory/stage.00001/swirrl_fileinfo.json
ln -s ~/data/staginghistory/stage.00001 ~/data/latest
download_working_dir_data ${NOTEBOOK_URL}/api/contents
delete_notebook https://swirrl.climate4impact.eu/swirrl-api/v1.0/notebook
